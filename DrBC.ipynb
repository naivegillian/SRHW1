{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"hw1__data.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"nwhw1_data\")\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "Task_name = 'nwhw1_data/hw1_data/Synthetic/5000'\n",
    "data_root = \"/home/p88101029/\"\n",
    "raw_data_base = os.path.join(data_root,Task_name)\n",
    "os.makedirs(raw_data_base, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "listoffolder=os.listdir(raw_data_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = []\n",
    "node_list = []\n",
    "for element in listoffolder:\n",
    "    if 'score' in element:\n",
    "        score_list.append(element)\n",
    "    if '_.' in element:\n",
    "        node_list.append(element)\n",
    "node_list=sorted(node_list)\n",
    "score_list=sorted(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from sklearn.preprocessing import normalize\n",
    "import torch.nn.functional as F\n",
    "\n",
    "n = 5000\n",
    "avg_degree = 50\n",
    "p = 0.5\n",
    "\n",
    "G = nx.powerlaw_cluster_graph(n, avg_degree, p)\n",
    "bc=nx.betweenness_centrality(G)\n",
    "data = from_networkx(G)\n",
    "data.x = torch.eye(n,n)\n",
    "data.y = F.normalize(torch.tensor([i for i in bc.values()]).reshape(-1,1), dim=0)\n",
    "\n",
    "n = 5000\n",
    "avg_degree = 50\n",
    "p = 0.5\n",
    "\n",
    "G2 = nx.powerlaw_cluster_graph(n, avg_degree, p)\n",
    "bc2=nx.betweenness_centrality(G2)\n",
    "data2 = from_networkx(G2)\n",
    "data2.x = torch.eye(n,n)\n",
    "data2.y = F.normalize(torch.tensor([i for i in bc2.values()]).reshape(-1,1), dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import degree, add_self_loops\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self):\n",
    "        super().__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        #edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "\n",
    "\n",
    "        # Step 3: Compute normalization.\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)+1\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Step 4-5: Start propagating messages.\n",
    "        out = self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def criterion(predicteddiff,targetdiff):\n",
    "    loss = -(torch.sigmoid(targetdiff))*torch.log2(torch.sigmoid(predicteddiff))-(1-torch.sigmoid(targetdiff))*torch.log2(1-torch.sigmoid(predicteddiff))\n",
    "    return torch.mean(loss)\n",
    "\n",
    "def get_samples(n):\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    for i in range(n*5):\n",
    "        num1 = random.randint(0, n-1)\n",
    "        num2 = random.randint(0, n-1)\n",
    "        while num1 == num2:\n",
    "            num2 = random.randint(0, n-1)\n",
    "        list1.append(num1)    \n",
    "        list2.append(num2)\n",
    "    list1=torch.tensor(list1)\n",
    "    list2=torch.tensor(list2)\n",
    "    return list1, list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DRBC(\n",
       "  (lin0): Linear(in_features=1, out_features=64, bias=False)\n",
       "  (GCNConv): GCNConv()\n",
       "  (gru): GRUCell(64, 64, bias=False)\n",
       "  (lin1): Linear(in_features=64, out_features=32, bias=False)\n",
       "  (lin2): Linear(in_features=32, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import GRUCell\n",
    "from torch.nn import Linear\n",
    "\n",
    "class DRBC(nn.Module):\n",
    "    def __init__(self, embedding_size, initialization_stddev, reg_hidden):\n",
    "        super().__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.initialization_stddev = initialization_stddev\n",
    "        self.reg_hidden = reg_hidden\n",
    "        self.lin0 = Linear(1,self.embedding_size,bias=False)\n",
    "        self.GCNConv = GCNConv()\n",
    "        self.gru = GRUCell(self.embedding_size,self.embedding_size,bias=False)\n",
    "        self.lin1 = Linear(self.embedding_size,self.reg_hidden,bias=False)\n",
    "        self.lin2 = Linear(self.reg_hidden,1,bias=False)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        deg = degree(edge_index[0]).cuda()\n",
    "        deg = torch.reshape(deg,(-1,1))\n",
    "        h0 = self.lin0(deg)\n",
    "        h1 = F.relu(h0)\n",
    "        h1 = F.normalize(h1, p=2, dim=1)\n",
    "        hn2=self.GCNConv(h1,edge_index)\n",
    "        h2 =self.gru(hn2,h1)\n",
    "        h2 = F.normalize(h2, p=2, dim=1)\n",
    "        hn3=self.GCNConv(h2,edge_index)\n",
    "        h3 =self.gru(hn3,h2)\n",
    "        h3 = F.normalize(h3, p=2, dim=1)\n",
    "        hn4=self.GCNConv(h3,edge_index)\n",
    "        h4 =self.gru(hn4,h3)\n",
    "        h4 = F.normalize(h4, p=2, dim=1)\n",
    "        hn5=self.GCNConv(h4,edge_index)\n",
    "        h5 =self.gru(hn5,h4)\n",
    "        h5 = F.normalize(h5, p=2, dim=1)\n",
    "        hs=torch.stack((h1,h2,h3,h4,h5),dim=2)\n",
    "        z=torch.max((hs),dim=2)\n",
    "        declay1 = self.lin1(h5)\n",
    "        declay2 = torch.relu(declay1)\n",
    "        betw_pred = self.lin2(declay2)     \n",
    "        return betw_pred\n",
    "\n",
    "model = DRBC(embedding_size=64, initialization_stddev=1, reg_hidden=32)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train tensor(0.99998558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96395999, device='cuda:0')\n",
      "train tensor(0.99998504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96307999, device='cuda:0')\n",
      "train tensor(0.99998528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96555996, device='cuda:0')\n",
      "train tensor(0.99998498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96399999, device='cuda:0')\n",
      "train tensor(0.99998420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96643996, device='cuda:0')\n",
      "train tensor(0.99998373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96503997, device='cuda:0')\n",
      "train tensor(0.99998391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96528000, device='cuda:0')\n",
      "train tensor(0.99998379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96528000, device='cuda:0')\n",
      "train tensor(0.99998391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96355999, device='cuda:0')\n",
      "train tensor(0.99998248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96503997, device='cuda:0')\n",
      "train tensor(0.99998295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96539998, device='cuda:0')\n",
      "train tensor(0.99998295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96423995, device='cuda:0')\n",
      "train tensor(0.99998194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96547997, device='cuda:0')\n",
      "train tensor(0.99998122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96711999, device='cuda:0')\n",
      "train tensor(0.99998182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96579999, device='cuda:0')\n",
      "train tensor(0.99997956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96743995, device='cuda:0')\n",
      "train tensor(0.99998152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96575999, device='cuda:0')\n",
      "train tensor(0.99997950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96307999, device='cuda:0')\n",
      "train tensor(0.99997920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96639997, device='cuda:0')\n",
      "train tensor(0.99997896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96599996, device='cuda:0')\n",
      "train tensor(0.99997872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96503997, device='cuda:0')\n",
      "train tensor(0.99997896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96303999, device='cuda:0')\n",
      "train tensor(0.99997902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96699995, device='cuda:0')\n",
      "train tensor(0.99997902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96587998, device='cuda:0')\n",
      "train tensor(0.99997777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96572000, device='cuda:0')\n",
      "train tensor(0.99997795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96511996, device='cuda:0')\n",
      "train tensor(0.99997669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96507996, device='cuda:0')\n",
      "train tensor(0.99997741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96691996, device='cuda:0')\n",
      "train tensor(0.99997854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96612000, device='cuda:0')\n",
      "train tensor(0.99997717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96591997, device='cuda:0')\n",
      "train tensor(0.99997699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96543998, device='cuda:0')\n",
      "train tensor(0.99997693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96679997, device='cuda:0')\n",
      "train tensor(0.99997604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96627998, device='cuda:0')\n",
      "train tensor(0.99997622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96587998, device='cuda:0')\n",
      "train tensor(0.99997574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96399999, device='cuda:0')\n",
      "train tensor(0.99997598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96471995, device='cuda:0')\n",
      "train tensor(0.99997485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96616000, device='cuda:0')\n",
      "train tensor(0.99997401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96436000, device='cuda:0')\n",
      "train tensor(0.99997449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96595997, device='cuda:0')\n",
      "train tensor(0.99997401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96483999, device='cuda:0')\n",
      "train tensor(0.99997526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96575999, device='cuda:0')\n",
      "train tensor(0.99997419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96311998, device='cuda:0')\n",
      "train tensor(0.99997342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96667999, device='cuda:0')\n",
      "train tensor(0.99997389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96563995, device='cuda:0')\n",
      "train tensor(0.99997258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96623999, device='cuda:0')\n",
      "train tensor(0.99997419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96627998, device='cuda:0')\n",
      "train tensor(0.99997443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96607995, device='cuda:0')\n",
      "train tensor(0.99997365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96392000, device='cuda:0')\n",
      "train tensor(0.99997199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96415997, device='cuda:0')\n",
      "train tensor(0.99997199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96787995, device='cuda:0')\n",
      "train tensor(0.99997294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96719998, device='cuda:0')\n",
      "train tensor(0.99997222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96664000, device='cuda:0')\n",
      "train tensor(0.99997288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96471995, device='cuda:0')\n",
      "train tensor(0.99997264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96687996, device='cuda:0')\n",
      "train tensor(0.99997187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96671999, device='cuda:0')\n",
      "train tensor(0.99997151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96515995, device='cuda:0')\n",
      "train tensor(0.99997169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96671999, device='cuda:0')\n",
      "train tensor(0.99997038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96551996, device='cuda:0')\n",
      "train tensor(0.99997264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96655995, device='cuda:0')\n",
      "train tensor(0.99997193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96616000, device='cuda:0')\n",
      "train tensor(0.99996936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96607995, device='cuda:0')\n",
      "train tensor(0.99997061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96635997, device='cuda:0')\n",
      "train tensor(0.99997073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96551996, device='cuda:0')\n",
      "train tensor(0.99997067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96767998, device='cuda:0')\n",
      "train tensor(0.99997240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96579999, device='cuda:0')\n",
      "train tensor(0.99997044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96451998, device='cuda:0')\n",
      "train tensor(0.99996984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96503997, device='cuda:0')\n",
      "train tensor(0.99997014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96524000, device='cuda:0')\n",
      "train tensor(0.99997121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96483999, device='cuda:0')\n",
      "train tensor(0.99996871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96439999, device='cuda:0')\n",
      "train tensor(0.99996942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96735996, device='cuda:0')\n",
      "train tensor(0.99996889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96359998, device='cuda:0')\n",
      "train tensor(0.99997008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96475995, device='cuda:0')\n",
      "train tensor(0.99996859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96568000, device='cuda:0')\n",
      "train tensor(0.99996996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96319997, device='cuda:0')\n",
      "train tensor(0.99997044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96447998, device='cuda:0')\n",
      "train tensor(0.99996966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96655995, device='cuda:0')\n",
      "train tensor(0.99996907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96603996, device='cuda:0')\n",
      "train tensor(0.99996734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96719998, device='cuda:0')\n",
      "train tensor(0.99996948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96664000, device='cuda:0')\n",
      "train tensor(0.99997061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96551996, device='cuda:0')\n",
      "train tensor(0.99996948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96528000, device='cuda:0')\n",
      "train tensor(0.99996763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96495998, device='cuda:0')\n",
      "train tensor(0.99996859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96395999, device='cuda:0')\n",
      "train tensor(0.99996668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96491998, device='cuda:0')\n",
      "train tensor(0.99996769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96731997, device='cuda:0')\n",
      "train tensor(0.99996787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96315998, device='cuda:0')\n",
      "train tensor(0.99996871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96511996, device='cuda:0')\n",
      "train tensor(0.99997008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96455997, device='cuda:0')\n",
      "train tensor(0.99996746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96568000, device='cuda:0')\n",
      "train tensor(0.99996823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96471995, device='cuda:0')\n",
      "train tensor(0.99996793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96607995, device='cuda:0')\n",
      "train tensor(0.99996716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96579999, device='cuda:0')\n",
      "train tensor(0.99996907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96543998, device='cuda:0')\n",
      "train tensor(0.99996924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96595997, device='cuda:0')\n",
      "train tensor(0.99996841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96455997, device='cuda:0')\n",
      "train tensor(0.99996740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96503997, device='cuda:0')\n",
      "train tensor(0.99996889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96579999, device='cuda:0')\n",
      "train tensor(0.99996793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96499997, device='cuda:0')\n",
      "train tensor(0.99996573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "valid tensor(0.96363997, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.00001)  # Define optimizer.\n",
    "torch.set_printoptions(precision=8)\n",
    "def train(data):\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    list1,list2 = get_samples(data.x.shape[0])\n",
    "    out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "    pred = out[list1]-out[list2]\n",
    "    trag = data.y[list1]-data.y[list2]\n",
    "    loss = criterion(pred, trag)  # Compute the loss solely based on the training nodes.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    return loss\n",
    "\n",
    "def valid(data):\n",
    "    model.eval()\n",
    "    list1,list2 = get_samples(data.x.shape[0])\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        pred = out[list1]-out[list2]\n",
    "        trag = data.y[list1]-data.y[list2]\n",
    "        acc=torch.mean((torch.sign(pred)==torch.sign(trag)).float())\n",
    "    return acc\n",
    "\n",
    "count=0\n",
    "bacc=0\n",
    "for epoch in range(10000):\n",
    "    data = data.to('cuda:0')\n",
    "    loss = train(data)\n",
    "    print(\"train\", loss)\n",
    "    data2 = data2.to('cuda:0')\n",
    "    acc = valid(data2)\n",
    "    print(\"valid\", acc)\n",
    "    if bacc < acc:\n",
    "        bacc = acc\n",
    "        count=0\n",
    "    else:\n",
    "        count+=1\n",
    "    if count==50:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from scipy import stats\n",
    "\n",
    "def topk_accuracy(k, pred, actu):\n",
    "    pt=pred.topk(k, dim=0).indices.squeeze().cpu().numpy()\n",
    "    at=actu.topk(k, dim=0).indices.squeeze().cpu().numpy()\n",
    "    intersection = np.intersect1d(pt, at)\n",
    "    count = len(intersection)\n",
    "    return count\n",
    "def return_rank(x):\n",
    "    x=x.cpu().numpy()\n",
    "    sorted_indices = np.argsort(x.squeeze())\n",
    "    ranks = np.zeros_like(sorted_indices)\n",
    "    ranks[sorted_indices] = np.arange(1, len(x) + 1)\n",
    "    return(ranks)\n",
    "def kendall_tau(x, y):\n",
    "    x=return_rank(x)\n",
    "    y=return_rank(y)\n",
    "    n_samples = len(x)\n",
    "    concordant_pairs = 0\n",
    "    discordant_pairs = 0\n",
    "    for i in range(n_samples):\n",
    "        for j in range(i + 1, n_samples):\n",
    "            if (x[i] < x[j] and y[i] > y[j]) or (x[i] > x[j] and y[i] < y[j]):\n",
    "                discordant_pairs += 1\n",
    "            else:\n",
    "                concordant_pairs += 1\n",
    "    tau = 2*(concordant_pairs - discordant_pairs) / (n_samples*(n_samples-1))\n",
    "    return tau\n",
    "def performance(model, edge_index, bc):\n",
    "    n=bc.shape[0]\n",
    "    onep=round(n*0.01)\n",
    "    fivep=round(n*0.05)\n",
    "    tenp=round(n*0.1)\n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "        out=model(1, edge_index)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        oneacc=topk_accuracy(onep,out,bc)/onep*100\n",
    "        fiveacc=topk_accuracy(fivep,out,bc)/fivep*100\n",
    "        tenacc=topk_accuracy(tenp,out,bc)/tenp*100\n",
    "        #kt=kendall_tau(out,bc)\n",
    "        kt=stats.kendalltau(out.cpu(),bc.cpu())\n",
    "        return(oneacc,fiveacc,tenacc,kt,elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_undirected\n",
    "perfreco=[]\n",
    "for (node_file,score_file) in zip(node_list,score_list):\n",
    "    pairedge=[]\n",
    "    with open('/home/p88101029/nwhw1_data/hw1_data/Synthetic/5000/'+node_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            pairedge.append(list(map(int,line.split())))\n",
    "    score=[]        \n",
    "    with open('/home/p88101029/nwhw1_data/hw1_data/Synthetic/5000/'+score_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            score.append([int(line.split()[0]),float(line.split()[1])])\n",
    "    edge_index = torch.tensor(pairedge).t().contiguous()\n",
    "    edge_index = to_undirected(edge_index)\n",
    "    y = torch.tensor([y[1] for y in score], dtype=torch.float)\n",
    "    edge_index=edge_index.to(device)\n",
    "    y=y.to(device)\n",
    "    perfreco.append(performance(model,edge_index,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(96.0, 82.39999999999999, 80.0, 0.47077031406281256, 0.15440034866333008), (90.0, 84.8, 79.80000000000001, 0.47369425885177036, 0.0035386085510253906), (92.0, 82.0, 77.4, 0.4683117423484697, 0.004873752593994141), (90.0, 80.4, 79.60000000000001, 0.4721133026605321, 0.005991458892822266), (88.0, 84.0, 78.0, 0.47655867173434685, 0.007806301116943359), (92.0, 81.2, 81.6, 0.47181644328865774, 0.0035245418548583984), (90.0, 83.6, 84.0, 0.49412170434086816, 0.003386259078979492), (92.0, 80.4, 82.39999999999999, 0.47381124224844967, 0.0039520263671875), (92.0, 81.6, 78.2, 0.46268549709941986, 0.0038955211639404297), (94.0, 86.8, 77.4, 0.47963128625725143, 0.0035767555236816406), (96.0, 85.2, 79.2, 0.480727825565113, 0.0037474632263183594), (90.0, 89.2, 80.4, 0.4809195439087818, 0.006331443786621094), (94.0, 84.0, 80.80000000000001, 0.4737741148229646, 0.0048675537109375), (94.0, 83.2, 79.60000000000001, 0.479750350070014, 0.004190206527709961), (92.0, 84.8, 80.4, 0.4691581516303261, 0.006150245666503906), (90.0, 83.2, 81.6, 0.4776240048009602, 0.005290508270263672), (92.0, 84.0, 81.39999999999999, 0.4849419483896779, 0.005383729934692383), (88.0, 84.39999999999999, 81.8, 0.47943300660132027, 0.004233598709106445), (94.0, 86.4, 78.60000000000001, 0.47189245849169836, 0.005059480667114258), (96.0, 84.39999999999999, 81.2, 0.4601545909181836, 0.005727052688598633), (90.0, 86.8, 78.0, 0.4652402480496099, 0.004803895950317383), (94.0, 86.4, 80.80000000000001, 0.4866629325865173, 0.004844188690185547), (88.0, 82.8, 79.80000000000001, 0.46757159431886375, 0.007013082504272461), (90.0, 82.8, 80.0, 0.46788493698739747, 0.005164146423339844), (96.0, 82.8, 81.0, 0.4905958791758352, 0.005725860595703125), (88.0, 84.39999999999999, 78.8, 0.47449217843568714, 0.004735469818115234), (88.0, 84.0, 79.0, 0.47258203640728147, 0.0042569637298583984), (94.0, 84.39999999999999, 79.0, 0.4690515703140628, 0.004791975021362305), (88.0, 82.8, 83.0, 0.4770989397879576, 0.003675699234008789), (94.0, 85.2, 82.8, 0.48277927585517105, 0.004626035690307617)]\n",
      "[9.17333333e+01 8.39466667e+01 8.01866667e+01 4.75195002e-01\n",
      " 9.85213916e-03]\n",
      "[2.66999792 1.9342067  1.66447856 0.00772965 0.02686275]\n"
     ]
    }
   ],
   "source": [
    "print(perfreco)\n",
    "print(np.mean(np.array(perfreco), axis=0))\n",
    "print(np.std(np.array(perfreco), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node_file in node_list:\n",
    "    with open('/home/p88101029/nwhw1_data/hw1_data/Synthetic/5000/'+node_file, 'r') as f:\n",
    "        pairedge=[]\n",
    "        for line in f.readlines():\n",
    "            pairedge.append(list(map(int,line.split())))\n",
    "        num_rows = len(pairedge)\n",
    "        header = '5000 '+str(num_rows)+'\\n'\n",
    "    with open('/home/p88101029/nwhw1_data/hw1_data/Synthetic/5000/'+node_file.replace(\"_.txt\",\"_.net\"), 'w') as f:\n",
    "        f.writelines(header)\n",
    "        for (x,y) in pairedge:\n",
    "            f.write('{} {}\\n'.format(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: Removing leading `/' from member names\r\n"
     ]
    }
   ],
   "source": [
    "!tar czf archive.tar.gz /home/p88101029/nwhw1_data/hw1_data/Synthetic/5000/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63.714864745792575,\n",
       " 66.53566896940646,\n",
       " 69.80588427072227,\n",
       " KendalltauResult(correlation=0.5370455517381877, pvalue=0.0),\n",
       " 0.32272911071777344)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairedge=[]\n",
    "with open('/home/p88101029/nwhw1_data/hw1_data/youtube/com-youtube.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        pairedge.append(list(map(int,line.split())))\n",
    "score=[]        \n",
    "with open('/home/p88101029/nwhw1_data/hw1_data/youtube/com-youtube_score.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        score.append([int(line.split()[0].replace(\":\",\"\")),float(line.split()[1])])\n",
    "edge_index = torch.tensor(pairedge).t().contiguous()\n",
    "edge_index = to_undirected(edge_index)\n",
    "y = torch.tensor([y[1] for y in score], dtype=torch.float)\n",
    "edge_index=edge_index.to(device)\n",
    "y=y.to(device)\n",
    "performance(model,edge_index,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
